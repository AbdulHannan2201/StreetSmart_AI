{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11ab4641-7996-4fc3-a2ad-ddac02a4d7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import torchvision.transforms.functional as F\n",
    "import timm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a5e91d7-76c5-4d67-883a-695734b18aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "data_dir = '/home/hannan/machineLearning/Dataset/BDD/dataset/dataset/augmented-512x512/train-augment-dataset/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55eb9111-6d5a-4c7f-8720-7725ed528c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model name\n",
    "model_name = \"vit_base_patch16_224\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06eed1f5-8af7-4378-ab4e-f0e2ea47d80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of classes\n",
    "num_classes = 7\n",
    " \n",
    "# Batch size\n",
    "batch_size = 16\n",
    " \n",
    "# Number of epochs\n",
    "num_epochs = 200\n",
    " \n",
    "# Flag for feature extracting\n",
    "feature_extract = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf3898ab-a79c-4c39-a02e-f17a9064dbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data transformations\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f689844-bdcc-4a86-afde-1053c53df9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val', 'test']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val', 'test']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}\n",
    "class_names = image_datasets['train'].classes\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af533d5e-6611-452a-97f7-a73e70ffb9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    " \n",
    "    if model_name == \"vit_base_patch16_224\":\n",
    "        model_ft = timm.create_model('vit_base_patch16_224', pretrained=use_pretrained, num_classes=num_classes)\n",
    "        input_size = 224\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    " \n",
    "    return model_ft, input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02023c71-3e94-42bb-b34f-265fa5d3f217",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=False)\n",
    "model_ft = model_ft.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c08bf53-d4e7-480e-9ecb-9fd653826c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft.load_state_dict(torch.load('best_model.pt', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309ad1f1-bd55-4985-85d3-d1b6e1daae50",
   "metadata": {},
   "source": [
    "## eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0875cc4f-e027-4b76-889c-9da29e1ef580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9871\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test data\n",
    "model_ft.eval()\n",
    "test_corrects = 0\n",
    "all_preds = []\n",
    "all_labels = []\n",
    " \n",
    "for inputs, labels in dataloaders['test']:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    " \n",
    "    outputs = model_ft(inputs)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    " \n",
    "    all_preds.extend(preds.cpu().numpy())\n",
    "    all_labels.extend(labels.cpu().numpy())\n",
    "    test_corrects += torch.sum(preds == labels.data)\n",
    " \n",
    "test_acc = test_corrects.double() / dataset_sizes['']\n",
    "print('Test Accuracy: {:.4f}'.format(test_acc))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a594964-30f0-4f98-8dfc-88f78ff39c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c93b631-98ec-4621-9d0b-f2e1d8cab841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix and classification report\n",
    "conf_mat = confusion_matrix(all_labels, all_preds)\n",
    "class_report = classification_report(all_labels, all_preds, target_names=class_names)\n",
    "print(\"Confusion Matrix:\\n\", conf_mat)\n",
    "print(\"Classification Report:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38033dc7-394c-4a6f-a1c4-76fd91f2f9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the labels and predictions to their corresponding class names\n",
    "actual_class_names = [class_names[label] for label in all_labels]\n",
    "predicted_class_names = [class_names[pred] for pred in all_preds]\n",
    "\n",
    "# Create the DataFrame\n",
    "res = pd.DataFrame({\"actual\": actual_class_names, \"predicted\": predicted_class_names})\n",
    "\n",
    "#res = pd.DataFrame( {\"actual\": all_labels, \"predicted\": all_preds})\n",
    "print(res)\n",
    "res.to_csv('best_model_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a799b9-ef75-4474-a192-5a8cca3335f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_mat, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('best_model_confusion_matrix.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b007e98-526a-4094-a487-3a5e78793a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and display evaluation metrics\n",
    "y_true = np.array(all_labels)\n",
    "y_pred = np.array(all_preds)\n",
    " \n",
    "accuracy = np.mean(y_true == y_pred)\n",
    "precision = np.diag(conf_mat) / np.sum(conf_mat, axis=0)\n",
    "recall = np.diag(conf_mat) / np.sum(conf_mat, axis=1)\n",
    "f1_score = 2 * precision * recall / (precision + recall)\n",
    " \n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Calculate and print the average precision, recall, and F1-score\n",
    "avg_precision = np.mean(precision)\n",
    "avg_recall = np.mean(recall)\n",
    "avg_f1_score = np.mean(f1_score)\n",
    "\n",
    "print(f\"Average Precision: {avg_precision:.4f}\")\n",
    "print(f\"Average Recall: {avg_recall:.4f}\")\n",
    "print(f\"Average F1-Score: {avg_f1_score:.4f}\")\n",
    " \n",
    "# Ensure the confusion matrix and the classification report are saved\n",
    "with open('best_model_classification_report.txt', 'w') as f:\n",
    "    f.write(f\"Classification Report:\\n{class_report}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
